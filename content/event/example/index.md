---
title: Optimal Algorithms for Stochastic Multi-Armed Bandits with Heavy-Tailed Rewards

event: NeurIPS 2020 Debriefing
event_url: http://www.timvanerven.nl/neurips-debriefing/

location: Via Zoom
# address:
 # street: 450 Serra Mall
 # city: Stanford
 # region: CA
 # postcode: '94305'
 # country: United States

summary: Presenting the above work from NeurIPS 2020 (by Kyungjae Lee, Hongjun Yang, Sungbin Lim and Songhwai Oh) at the yearly NeurIPS debriefing for AI researchers in the Netherlands. The full work may be found at https://papers.nips.cc/paper/2020/file/607bc9ebe4abfcd65181bfbef6252830-Paper.pdf. "Optimal Algorithms for Stochastic Multi-Armed Bandits with Heavy Tailed Rewards Kyungjae Lee, Hongjun Yang, Sungbin Lim, Songhwai Oh, NeurIPS pre-proceedings 2020".
abstract: "In this paper, we consider stochastic multi-armed bandits (MABs) with heavy-tailed
rewards, whose p-th moment is bounded by a constant νp for 1 < p ≤ 2. First, we
propose a novel robust estimator which does not require νp as prior information,
while other existing robust estimators demand prior knowledge about νp. We show
that an error probability of the proposed estimator decays exponentially fast. Using
this estimator, we propose a perturbation-based exploration strategy and develop a
generalized regret analysis scheme that provides upper and lower regret bounds by
revealing the relationship between the regret and the cumulative density function
of the perturbation. From the proposed analysis scheme, we obtain gap-dependent
and gap-independent upper and lower regret bounds of various perturbations. We
also find the optimal hyperparameters for each perturbation, which can achieve
the minimax optimal regret bound with respect to total rounds. In simulation,
the proposed estimator shows favorable performance compared to existing robust
estimators for various p values and, for MAB problems, the proposed perturbation
strategy outperforms existing exploration methods."

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
  date: "2030-06-01T13:00:00Z"
# date_end: "2030-06-01T15:00:00Z"
  all_day: false

# Schedule page publish date (NOT talk date).
 publishDate: "2021-01-01T00:00:00Z"

authors: []
tags: []

# Is this a featured talk? (true/false)
featured: false

image:
  caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/bzdhc5b3Bxs)'
  focal_point: Right

links: []
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []

# {{% callout note %}}
# Click on the **Slides** button above to view the built-in slides feature.
# {{% /callout %}}

# Slides can be added in a few ways:

# - **Create** slides using Wowchemy's [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
# - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
# - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

# Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page.
